{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install transformers\n",
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from semantic_cipher import SemanticCipher\n",
    "\n",
    "# Only needed if models are downloaded from huggingface\n",
    "os.environ['HF_TOKEN'] = '<hugging_face_token>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode using OpenAI GPT-4o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use OpenAI models, simply add your OpenAI API key to the `.env` file.\n",
    "\n",
    "The `encode` method requires one parameter, `plaintext`, which is the textual data that is to be semantically enciphered.\n",
    "\n",
    "Two optional parameters can be used:\n",
    "\n",
    "* The `context` param notifies the LLM that the generated output should be relevant to the given topic.\n",
    "* The `key` param shuffles the hex mapping so that the end user must know the key in order for the text to be decoded.\n",
    "\n",
    "There are `16!` total permutations, given that the encoding list contains all hexadecimal characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 16:02:06,957 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 16:02:07,597 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 16:02:08,266 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciphertext: Launching every day, fearless astronauts will always conquer all universe. Astronauts wearing advanced technology aboard craft achieve cosmic adventures always\n",
      "Plaintext: 0xdeadbeef\n"
     ]
    }
   ],
   "source": [
    "sc = SemanticCipher(model_name=\"gpt-4o\")\n",
    "ciphertext = sc.encode(plaintext=\"0xdeadbeef\", context=\"Space\", key=\"xyz\")\n",
    "print(f\"Ciphertext: {ciphertext}\")\n",
    "plaintext = sc.decode(ciphertext)\n",
    "print(f\"Plaintext: {plaintext}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode using pretrained SLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** Using SLM's typically output text that is erroneous and or illogical.  Next token prediction is stricly used and does not use the reasoning capabilities of larger models to formulate outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciphertext: Lily E. Duffin F. A. W. A. C. A. U. A. W. A. T. A. C. A. C. A. A.\n",
      "Plaintext: 0xdeadbeef\n"
     ]
    }
   ],
   "source": [
    "sc = SemanticCipher(model_name=\"Qwen/Qwen2.5-1.5B-Instruct\", from_pretrained=True)\n",
    "ciphertext = sc.encode(\"0xdeadbeef\", key=\"xyz\")\n",
    "print(f\"Ciphertext: {ciphertext}\")\n",
    "plaintext = sc.decode(ciphertext)\n",
    "print(f\"Plaintext: {plaintext}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SemanticCipher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
